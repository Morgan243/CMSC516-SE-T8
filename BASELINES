####
# Published Baselines
Models are measured using the F1 Score - the harmonic mean of precision and recall. The authors
of the SemEval 2018 task demonstrated baselines with an SVM and Naive Bayes classifier.
           Naive Bayes      SVM
f1         0.632            0.605


####
# Team Baselines
In order to both acquaint ourselves with the problem and to set our own baselines, we compare
Naive Bayes with a handful of tree-based classifiers. Tree-based classifiers were chosen because
they are generally quick to train and are capable of high variance

           Decision Tree  Gradient Boosting  Naive Bayes  Random Forest
f1              0.401396           0.567398     0.590962       0.264317

As shown above, we find Naive Bayes still performing best by making a more fair tradeoff between precision
and recall. The tree based classifiers tended towards high precision, though this may due to an insufficient
parameter search, evident by our Naive Bayes classifier failing to perform as well as the authors. Also,
we thresholded our document frequency minimum for BOW vectorization, which presumably may boost results.

####
# Team Results - GloVe Embeddings + LSTM
Our best results were achieved with this more complex model:

f1      0.676
